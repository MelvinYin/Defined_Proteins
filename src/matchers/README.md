# Phipsi

Phipsi takes in list of all phipsi angles for that particular sno position. If all angles are at 360., matcher_weight is set to 0 and probs return a np.array of all 0s with length of input phipsis, for all query datapoint inputs.

For any angles that are at 360 at the load phase, it is ignored during subsequent calculations. At query probs output, a 0. will be inserted at that position, meaning no match whatsoever. 

Otherwise, the phipsi angles form a 2D landscape, spanning -180 => 180 for both, with periodic boundary conditions. This results in a toroidal space. The clustering algorithm used (bayesian gaussian mixture from sklearn) does not allow for consideration of BCs, so this has to be factored in manually.

What we are concerned about are clusters that span, for instance, -150 to -210/150 degrees. It will appear as two separate clusters at both ends of the x-axis, resulting in it being considered as two gaussian clusters. Instead, we first take the median for each dimension, and subtract this value from all input phipsi angles. Phipsi angles are then normalised to be between -180 and 180. We take median because taking mean results in a centre point when the main cluster is split to both ends of the -180/180 range. We simply wish to position as much as possible the cluster towards the centre of the plot, so that the gaussian mixture can correctly identify any wide-spanning cluster as a single unsplit cluster. 

Next, these phipsi angles are fed into the clustering algorithm, bayesian gaussian mixture, or BGM. BGM attempts to fit gaussian distributions onto the datapoints, by (in brief) maximising the probability that the datapoints are as sampled, given the estimated underlying distribution. Each cluster has an associated weight, which describes how relevant it is to the overall distribution. To minimise the number of clusters we have to deal with while avoiding having to manually set the number the clusters, we first set a high number for number of clusters. Then, the number of clusters with weight above a threshold value (0.05) are counted and a new BGM created and fitted. This effectively keeps only the large significant clusters.

Next, to get matcher_weight, we need some parameter that describes how well clustered the phipsi angles are. Precision, effectively the inverse of the covariance matrices, is used, and we take the mean of all clusters (summing will mean having more clusters result in a higher precision score). matcher_weight should not only depend on the dataset distribution. For instance, even if the phipsi angles are tightly clustered but the queried angles do not fit the distribution, phipsi_matcher should not be given a large weight because chances are that particular queried node just does not experience the constraints usually felt by nodes in that position. Therefore, the matcher_weight is a product of the precision score and the score that the queried node actually belongs to the distribution (which may consist of multiple gaussians). A translation factor of +9.69, determined by the score of a point that is the mean of one of the clusters, is used to normalise somewhat the returned score. Finally, two scaling factors, one for the precision value and one for the queried score, are used to bring the final matcher_weight closer to what the others matchers would give. 

For obtaining the matching score of the queried node with each phipsi value pair, we will be using the multivariate form of the standard gaussian cdf calculation, namely (x-miu)/sigma. The equivalent multivariate form would be (X-miu) * covariance_inv * (X-miu).T. There are two concerns here, first that cov_inv should be weighted for each cluster, and second that miu need to be replaced with each phipsi value. 

Essentially, we are trying to find some parameter that describes how "far" the queried point is from the dataset point. It is tempting to find the nearest cluster to the phipsi/queried, possibly by finding the euclidean distance to the means, and then use that cov matrix. The problem is, BGM simply fits clusters that best describe the distribution. Therefore, the clusters are definitely not necessarily accurate. What if the nearest cluster happens to have a very tight covariance, leading to a much larger estimated distance. Instead, BGM provides a set of weights that it assign to each cluster, describing how "relevant" they are to the overall distribution. We can simply multiply this weight with the inv_cov to get a consolidated inv_cov, that somewhat describes the overall distribution. Then, taking (X-Y) where Y is the dataset point should result in a good approximation for the distance. Taking (X-Y) essentially centers the normal distribution on the Y point, and we calculate the cdf of X occuring with Y as mean.

What about the periodic BCs though? If we consider what a pdf stands for, imagine a circle that describes the range of phi. Because the pdf is symmetric, we can draw a diameter chord that bisects the circle. If at one point there is the mean of a normal distribution, at the second will be the "minimum" point. Because all points must lie on this circle, taking the cdf essentially means integrating the pdf across all but a subset of the circle, where the mean is at the centre. In 2D, the edges would form a probability contour. Therefore, integrating as such does give the proper cdf with periodic BCs. 

# Signature

Signature matcher_weight currently gives the relative proportion of the top two highest represented res. This gives weight to highly conserved points. Returned probability is 1 if the residues match, or the blosum value (normalised to 0 => 1) if they don't. 

# Hbond

Hbond is currently rather crude, with a fixed matcher_weight of 0.5 and rather bad probability estimates. The issue is that each hbond has several properties, and it is not clear how these should be related/weighted relative to each other. For instance, bond length vs category vs angles of bonds. Having a hbond in one configuration does not mean that the same node cannot have multiple or no hbond in the next, without significantly affecting stability of the structure or its free energy. 

# ContactMatcher and CovalentMatcher

Essentially a binary hit/miss probability. Weight is currently 0.5 as well, it can be defined better in say the relative proportion of bonds, but considering that in the current dataset, it's only 1-2 points that give 7 and 1 and the rest give 0, without a larger dataset and more information on how these affect the matching, any effort will be no different from speculation. 